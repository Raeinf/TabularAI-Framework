{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory managing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Get the sizes of all variables\n",
    "vars_with_sizes = {name: sys.getsizeof(obj) for name, obj in globals().items()}\n",
    "\n",
    "# Sort by size in descending order\n",
    "sorted_vars = sorted(vars_with_sizes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print variables with their sizes\n",
    "for name, size in sorted_vars:\n",
    "    print(f\"{name}: {size} bytes\")\n",
    "\n",
    "\n",
    "# del variable_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import warnings\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Numerical and Statistical Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning Models\n",
    "# Regression Models\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Neural Networks (NN)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, callbacks\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# FastAI\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, mutual_info_classif, mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import PowerTransformer, PolynomialFeatures\n",
    "from geopy.distance import geodesic, great_circle\n",
    "\n",
    "# Data Preprocessing and Encoding\n",
    "# Scalers\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    MultiLabelBinarizer,\n",
    ")\n",
    "\n",
    "# Encoders\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "# Imputation\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "\n",
    "\n",
    "# Resampling\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Model Tuning and Evaluation\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    log_loss,\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error,\n",
    "    explained_variance_score,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "# AutoML\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Optuna for Hyperparameter Tuning\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"../input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pahts\n",
    "train_path = \"../\"\n",
    "test_path = \"../\"\n",
    "\n",
    "# importing data\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "# train_ = pd.read_csv(train_path)  # Copies\n",
    "# test_ = pd.read_csv(test_path)  # Copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(df, columns):\n",
    "    df[columns] = df[columns].apply(pd.to_datetime)\n",
    "    return df\n",
    "\n",
    "\n",
    "# df = convert_to_datetime(df, ['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"\"\n",
    "y = train[target_col]\n",
    "train = train.drop(target_col, axis=1)\n",
    "\n",
    "num_cols = train.select_dtypes(include=[\"number\"]).columns\n",
    "cat_cols = train.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "date_cols = train.select_dtypes(include=[\"datetime\"]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of train\", train.shape)\n",
    "print(\"shape of test\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce data size if it is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "def reduce_memory_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        # Handle float64 type\n",
    "        if col_type == \"float64\":\n",
    "            # Convert float to int if no decimals\n",
    "            if (df[col] % 1 == 0).all():\n",
    "                print(f\"Converting {col} from {col_type} to int64\")\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "\n",
    "        # Handle int64 type\n",
    "        if col_type == \"int64\":\n",
    "            # Convert to smaller int types based on value range\n",
    "            if (\n",
    "                df[col].min() >= np.iinfo(np.int8).min\n",
    "                and df[col].max() <= np.iinfo(np.int8).max\n",
    "            ):\n",
    "                print(f\"Converting {col} from int64 to int8\")\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif (\n",
    "                df[col].min() >= np.iinfo(np.int16).min\n",
    "                and df[col].max() <= np.iinfo(np.int16).max\n",
    "            ):\n",
    "                print(f\"Converting {col} from int64 to int16\")\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif (\n",
    "                df[col].min() >= np.iinfo(np.int32).min\n",
    "                and df[col].max() <= np.iinfo(np.int32).max\n",
    "            ):\n",
    "                print(f\"Converting {col} from int64 to int32\")\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# df = reduce_memory_usage(df)\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some init procces like jason & Regex & str_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting jason features\n",
    "import json\n",
    "import ast\n",
    "\n",
    "\n",
    "def extract_features(json_str):\n",
    "    features_list = json.loads(json_str)  # Use json.loads() to parse the JSON string\n",
    "    return {item[\"name\"]: item[\"description\"] for item in features_list}\n",
    "\n",
    "\n",
    "# Assuming df is already defined and contains the 'features' column\n",
    "# features_df = df['features'].apply(extract_features).apply(pd.Series)\n",
    "\n",
    "# df = pd.concat([df, features_df], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_engine(df):\n",
    "    df[\"horsepower\"] = df[\"engine\"].str.extract(r\"(\\d+\\.\\d+)(?=HP)\").astype(float)\n",
    "    df[\"engine_size\"] = df[\"engine\"].str.extract(r\"(\\d+\\.\\d+)(?=L)\").astype(float)\n",
    "    df[\"cylinders\"] = (\n",
    "        df[\"engine\"].str.extract(r\"(\\d+)\\s(Cylinder|V\\d|Straight)\")[0].astype(float)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## str_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_split(df):\n",
    "    df[[\"Type\", \"Level\"]] = (  # Create two new features\n",
    "        df[\n",
    "            \"Policy\"\n",
    "        ].str.split(  # from the Policy feature  # through the string accessor\n",
    "            \" \", expand=True\n",
    "        )  # by splitting on \" \"\n",
    "        # and expanding the result into separate columns\n",
    "    )\n",
    "\n",
    "    df[[\"Policy\", \"Type\", \"Level\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make other columns into yours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_rows(row):\n",
    "    crimes = [\n",
    "        row[\"Crm Cd\"],\n",
    "        row[\"Crm Cd 1\"],\n",
    "        row[\"Crm Cd 2\"],\n",
    "        row[\"Crm Cd 3\"],\n",
    "        row[\"Crm Cd 4\"],\n",
    "    ]\n",
    "    result = []\n",
    "\n",
    "    row = row.drop([\"Crm Cd 1\", \"Crm Cd 2\", \"Crm Cd 3\", \"Crm Cd 4\"])\n",
    "    for crime in crimes:\n",
    "        if not np.isnan(crime):\n",
    "            row[\"Crm Cd\"] = crime\n",
    "            result.append(row)\n",
    "    return result\n",
    "\n",
    "\n",
    "# expanded_train = train.apply(make_new_rows, axis=1)\n",
    "# train = pd.DataFrame([item for sublist in expanded_train for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_combined = pd.concat([train, y], axis=1)\n",
    "print(\"Duplicated Rows:\", train_target_combined.duplicated().sum())\n",
    "# train_target_combined = train_target_combined.drop_duplicates()\n",
    "\n",
    "# Separate the train and target back\n",
    "train = train_target_combined.iloc[:, :-1]\n",
    "y = train_target_combined.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of train\", train.shape)\n",
    "print(\"shape of test\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_info(df):\n",
    "    \"\"\"Calculate\n",
    "    count of unique,\n",
    "    unique values,\n",
    "    count & % of missing values,\n",
    "    data types of the columns\"\"\"\n",
    "    nunique = df.nunique()\n",
    "    unique = df.apply(lambda x: x.unique())\n",
    "    missing_count = df.isna().sum()\n",
    "    missing_percentage = round((df.isna().sum() / len(df)) * 100, 2)\n",
    "    dtypes = df.dtypes\n",
    "\n",
    "    # combine metrics into a single DataFrame\n",
    "    agg_df = pd.DataFrame(\n",
    "        {\n",
    "            \"nunique values\": nunique,\n",
    "            \"unique\": unique,\n",
    "            \"missing_count\": missing_count,\n",
    "            \"missing_percentage\": missing_percentage,\n",
    "            \"dtypes\": dtypes,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "aggregate_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_summary(df):\n",
    "    obs = df.shape[0]\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=\"number\")\n",
    "    summary_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Dtype\": numeric_df.dtypes,\n",
    "            \"Counts\": numeric_df.apply(lambda x: x.count()),\n",
    "            \"Nulls\": numeric_df.apply(lambda x: x.isnull().sum()),\n",
    "            \"NullPercent\": (numeric_df.isnull().sum() / obs) * 100,\n",
    "            \"Mean\": numeric_df.mean(),\n",
    "            \"Min\": numeric_df.min(),\n",
    "            \"Max\": numeric_df.max(),\n",
    "            \"Uniques\": numeric_df.apply(lambda x: x.unique().shape[0]),\n",
    "            \"UniqueValues\": numeric_df.apply(\n",
    "                lambda x: list(x.unique()) if x.nunique() <= 10 else \"-\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "numeric_summary(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_values(df, fill_value):\n",
    "    return df.fillna(fill_value)\n",
    "\n",
    "\n",
    "# df = fill_na_values(df, -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_na(df, drop=\"cols\"):\n",
    "\n",
    "    if drop == \"cols\":\n",
    "        cols_with_missing = [col for col in df.columns if df[col].isnull().any()]\n",
    "        return df.drop(cols_with_missing, axis=1)\n",
    "    elif drop == \"rows\":\n",
    "        return df.dropna(how=\"any\")\n",
    "    else:\n",
    "        raise ValueError(\"Parameter 'drop' must be either 'rows' or 'cols'.\")\n",
    "\n",
    "\n",
    "# df = drop_na(df, \"rows\")\n",
    "# df = drop_na(df, \"cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_train_test(df, strategy=\"mean\"):  # can also use median or most_frequent\n",
    "\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# df = impute_train_test(df)\n",
    "\n",
    "# df = impute_train_test(df,\"median\")\n",
    "\n",
    "# df = impute_train_test(df,\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for time series\n",
    "# df = df.fillna(method=\"ffill\")\n",
    "# df = df.fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate\n",
    "# df = df.interpolate(method=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer()\n",
    "# df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaion + balance + outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target_distribution(target):\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(target):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(target, kde=True, bins=30, color=\"blue\")\n",
    "        plt.title(f\"Distribution of Numerical Target\", fontsize=14)\n",
    "        plt.xlabel(target.name, fontsize=12)\n",
    "        plt.ylabel(\"Frequency\", fontsize=12)\n",
    "    else:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.countplot(x=target, palette=\"Set2\")\n",
    "        plt.title(f\"Distribution of Categorical Target\", fontsize=14)\n",
    "        plt.xlabel(target.name, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_target_distribution(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balance the target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_target(target, method=\"log\", reverse=False, c=0):\n",
    "    target_transformed = target.copy()\n",
    "\n",
    "    if not reverse:\n",
    "        if method == \"log\":\n",
    "            target_transformed = np.log1p(target_transformed + c)\n",
    "        elif method == \"sqrt\":\n",
    "            target_transformed = np.sqrt(target_transformed + c)\n",
    "        elif method == \"boxcox\":\n",
    "            target_transformed, _ = stats.boxcox(\n",
    "                target_transformed + 1e-9\n",
    "            )  # Add small value to handle 0\n",
    "        elif method == \"reciprocal\":\n",
    "            target_transformed = 1 / (target_transformed + 1e-9)\n",
    "        elif method == \"yeo-johnson\":\n",
    "            pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "            target_transformed = pt.fit_transform(\n",
    "                target_transformed.values.reshape(-1, 1)\n",
    "            ).flatten()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid method. Choose from 'log', 'sqrt', 'boxcox', 'reciprocal', 'yeo-johnson'.\"\n",
    "            )\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(target_transformed, kde=True, bins=30, color=\"green\")\n",
    "        plt.title(f\"{method.capitalize()} Transformation of Target\", fontsize=14)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        if method == \"log\":\n",
    "            target_transformed = np.expm1(target_transformed)\n",
    "        elif method == \"sqrt\":\n",
    "            target_transformed = target_transformed**2\n",
    "        elif method == \"boxcox\":\n",
    "            target_transformed = stats.inv_boxcox(target_transformed, _)\n",
    "        elif method == \"reciprocal\":\n",
    "            target_transformed = 1 / target_transformed\n",
    "        elif method == \"yeo-johnson\":\n",
    "            pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "            target_transformed = pt.inverse_transform(\n",
    "                target_transformed.values.reshape(-1, 1)\n",
    "            ).flatten()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid method for reversing. Choose from 'log', 'sqrt', 'boxcox', 'reciprocal', 'yeo-johnson'.\"\n",
    "            )\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(target_transformed, kde=True, bins=30, color=\"blue\")\n",
    "        plt.title(\n",
    "            f\"Reverse {method.capitalize()} Transformation of Target\", fontsize=14\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    return pd.Series(target_transformed, index=target.index)\n",
    "\n",
    "\n",
    "# y = transform_target(y, method=\"log\", reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resampling / undersampling /both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESAMPLING\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "\n",
    "cat_cols_idx = [train.columns.get_loc(col) for col in cat_cols]\n",
    "smote_nc = SMOTENC(categorical_features=cat_cols_idx, random_state=42)\n",
    "\n",
    "# train, y = smote.fit_resample(train, y)\n",
    "# train, y = smote_nc.fit_resample(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under Sampling\n",
    "\n",
    "undersample = RandomUnderSampler(random_state=42)\n",
    "# train, y = undersample.fit_resample(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination\n",
    "\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "# train, y = smote_enn.fit_resample(train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_numerical_columns(train, test, num_cols):\n",
    "    fig, axs = plt.subplots(len(num_cols), 2, figsize=(12, len(num_cols) * 4))\n",
    "\n",
    "    # If there's only one numerical column, ensure axs is treated as 2D\n",
    "    if len(num_cols) == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        min_val = min(train[col].min(), test[col].min())\n",
    "        max_val = max(train[col].max(), test[col].max())\n",
    "\n",
    "        sns.histplot(\n",
    "            train[col], ax=axs[i, 0], color=\"blue\", kde=True, label=\"Train\", bins=20\n",
    "        )\n",
    "        axs[i, 0].set_title(f\"Train - {col}\")\n",
    "        axs[i, 0].set_xlim(min_val, max_val)\n",
    "\n",
    "        sns.histplot(\n",
    "            test[col], ax=axs[i, 1], color=\"red\", kde=True, label=\"Test\", bins=20\n",
    "        )\n",
    "        axs[i, 1].set_title(f\"Test - {col}\")\n",
    "        axs[i, 1].set_xlim(min_val, max_val)\n",
    "\n",
    "        axs[i, 0].set_xlabel(\"Value\")\n",
    "        axs[i, 0].set_ylabel(\"Frequency\")\n",
    "        axs[i, 1].set_xlabel(\"Value\")\n",
    "        axs[i, 1].set_ylabel(\"Frequency\")\n",
    "        axs[i, 0].legend()\n",
    "        axs[i, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# compare_numerical_columns(train, test, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(train, test, num_cols, transformation=None, c=0):\n",
    "    train_transformed = train.copy()\n",
    "    test_transformed = test.copy()\n",
    "\n",
    "    for col in num_cols:\n",
    "        if transformation == \"log\":\n",
    "            train_transformed[col] = np.log1p(train_transformed[col] + c)\n",
    "            test_transformed[col] = np.log1p(test_transformed[col] + c)\n",
    "        elif transformation == \"sqrt\":\n",
    "            train_transformed[col] = np.sqrt(train_transformed[col] + c)\n",
    "            test_transformed[col] = np.sqrt(test_transformed[col] + c)\n",
    "        elif transformation == \"square\":\n",
    "            train_transformed[col] = np.square(train_transformed[col] + c)\n",
    "            test_transformed[col] = np.square(test_transformed[col] + c)\n",
    "\n",
    "    fig, axs = plt.subplots(len(num_cols), 2, figsize=(12, len(num_cols) * 4))\n",
    "\n",
    "    if len(num_cols) == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        min_val = min(train_transformed[col].min(), test_transformed[col].min())\n",
    "        max_val = max(train_transformed[col].max(), test_transformed[col].max())\n",
    "\n",
    "        sns.histplot(\n",
    "            train_transformed[col],\n",
    "            ax=axs[i, 0],\n",
    "            color=\"blue\",\n",
    "            kde=True,\n",
    "            label=\"Train\",\n",
    "            bins=20,\n",
    "        )\n",
    "        axs[i, 0].set_title(f\"Train - {col} ({transformation})\")\n",
    "        axs[i, 0].set_xlim(min_val, max_val)\n",
    "\n",
    "        sns.histplot(\n",
    "            test_transformed[col],\n",
    "            ax=axs[i, 1],\n",
    "            color=\"red\",\n",
    "            kde=True,\n",
    "            label=\"Test\",\n",
    "            bins=20,\n",
    "        )\n",
    "        axs[i, 1].set_title(f\"Test - {col} ({transformation})\")\n",
    "        axs[i, 1].set_xlim(min_val, max_val)\n",
    "\n",
    "        axs[i, 0].set_xlabel(\"Value\")\n",
    "        axs[i, 0].set_ylabel(\"Frequency\")\n",
    "        axs[i, 1].set_xlabel(\"Value\")\n",
    "        axs[i, 1].set_ylabel(\"Frequency\")\n",
    "        axs[i, 0].legend()\n",
    "        axs[i, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return train_transformed, test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### more plot on numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scater like plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_kde(df, num_cols):\n",
    "    plt.figure(figsize=(12, len(num_cols) * 4))\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(len(num_cols), 1, i + 1)\n",
    "        sns.histplot(df[col], kde=True, bins=30, color=\"blue\")\n",
    "        plt.title(f\"Histogram and KDE of {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_histogram_kde(train, num_cols)\n",
    "\n",
    "\n",
    "def plot_scatter_with_numerical_target(df, num_cols, target):\n",
    "    plt.figure(figsize=(12, len(num_cols) * 4))\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(len(num_cols), 1, i + 1)\n",
    "        sns.scatterplot(x=df[col], y=target, color=\"blue\")\n",
    "        plt.title(f\"Scatter Plot: {col} vs Target\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Target\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_scatter_with_numerical_target(train, num_cols, y)\n",
    "\n",
    "\n",
    "def plot_lmplot_with_numerical_target(df, num_cols, target):\n",
    "    plt.figure(figsize=(12, len(num_cols) * 4))\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(len(num_cols), 1, i + 1)\n",
    "        sns.regplot(\n",
    "            x=df[col],\n",
    "            y=target,\n",
    "            scatter_kws={\"color\": \"blue\"},\n",
    "            line_kws={\"color\": \"red\"},\n",
    "        )\n",
    "        plt.title(f\"Scatter Plot with Linear Regression: {col} vs Target\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Target\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_lmplot_with_numerical_target(train, num_cols, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot(df, num_cols):\n",
    "    plt.figure(figsize=(12, len(num_cols) * 4))\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(len(num_cols), 1, i + 1)\n",
    "        sns.boxplot(x=df[col], color=\"green\")\n",
    "        plt.title(f\"Boxplot of {col}\")\n",
    "        plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_boxplot(train, num_cols)\n",
    "\n",
    "\n",
    "def plot_boxplot_with_numerical_target(df, num_cols, target):\n",
    "    plt.figure(figsize=(12, len(num_cols) * 4))\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(len(num_cols), 1, i + 1)\n",
    "        sns.boxplot(y=df[col], x=target, color=\"lightblue\")\n",
    "        plt.title(f\"Boxplot of {col} by Target\")\n",
    "        plt.ylabel(col)\n",
    "        plt.xlabel(\"Target\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_boxplot_with_numerical_target(train, num_cols, y)\n",
    "\n",
    "\n",
    "def plot_boxplot_with_categorical_target(df, num_cols, target):\n",
    "    plt.figure(figsize=(12, len(num_cols) * 4))\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(len(num_cols), 1, i + 1)\n",
    "        sns.boxplot(x=target, y=df[col], color=\"lightgreen\")\n",
    "        plt.title(f\"Boxplot of {col} by Categorical Target\")\n",
    "        plt.xlabel(\"Target\")\n",
    "        plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_boxplot_with_categorical_target(train, num_cols, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violinplot(df, num_cols):\n",
    "    plt.figure(figsize=(12, len(num_cols) * 4))\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(len(num_cols), 1, i + 1)\n",
    "        sns.violinplot(x=df[col], color=\"lightblue\")\n",
    "        plt.title(f\"Violin Plot of {col}\")\n",
    "        plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_violinplot(train, num_cols)\n",
    "\n",
    "\n",
    "def plot_violin_with_categorical_target(df, num_cols, target):\n",
    "    plt.figure(figsize=(12, len(num_cols) * 4))\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(len(num_cols), 1, i + 1)\n",
    "        sns.violinplot(x=target, y=df[col], color=\"lightblue\")\n",
    "        plt.title(f\"Violin Plot of {col} by Categorical Target\")\n",
    "        plt.xlabel(\"Target\")\n",
    "        plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_violin_with_categorical_target(train, num_cols, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers_iqr(df, target, num_cols, method=\"remove\"):\n",
    "    df_out = df.copy()\n",
    "\n",
    "    for col in num_cols:\n",
    "        Q1 = df_out[col].quantile(0.25)\n",
    "        Q3 = df_out[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        if method == \"remove\":\n",
    "            # Create a boolean mask for outliers\n",
    "            mask = (df_out[col] >= lower_bound) & (df_out[col] <= upper_bound)\n",
    "            df_out = df_out[mask]\n",
    "            target = target[mask]  # Align the target with the remaining DataFrame\n",
    "        elif method == \"replace\":\n",
    "            df_out[col] = df_out[col].where(\n",
    "                (df_out[col] >= lower_bound) & (df_out[col] <= upper_bound),\n",
    "                other=df_out[\n",
    "                    col\n",
    "                ].mean(),  # Replace with the mean or other value if outlier\n",
    "            )\n",
    "\n",
    "    return df_out, target  # Return the modified DataFrame and target\n",
    "\n",
    "\n",
    "train, y = handle_outliers_iqr(train, y, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairplot(df, num_cols):\n",
    "    sns.pairplot(df[num_cols])\n",
    "    plt.suptitle(\"Pair Plot of Numerical Features\", y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_pairplot(train, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lower_triangle_heatmap(df, cols):\n",
    "\n",
    "    corr = df[cols].corr()\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        cmap=\"coolwarm\",\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        square=True,\n",
    "        cbar_kws={\"shrink\": 0.8},\n",
    "    )\n",
    "\n",
    "    plt.title(\"Correlation Heatmap (Lower Triangle)\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_lower_triangle_heatmap(train, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Drop highly corrolated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly corrolated features\n",
    "\n",
    "drop_cols = []\n",
    "train = train.drop(drop_cols, axis=1)\n",
    "test = test.drop(drop_cols, axis=1)\n",
    "num_cols = train.select_dtypes(include=np.number).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare target and cats distribuion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_categorical_columns(train, test, cat_cols):\n",
    "    for cat_col in cat_cols:\n",
    "        # Get all unique categories from both train and test\n",
    "        categories = sorted(\n",
    "            list(set(train[cat_col].unique()) | set(test[cat_col].unique()))\n",
    "        )\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "        # Plot for the train set with consistent category order\n",
    "        sns.countplot(\n",
    "            data=train, x=cat_col, palette=\"Set2\", ax=axs[0], order=categories\n",
    "        )\n",
    "        axs[0].set_title(f\"Train - {cat_col}\", fontsize=16)\n",
    "        axs[0].set_xlabel(cat_col, fontsize=12)\n",
    "        axs[0].set_ylabel(\"Count\", fontsize=12)\n",
    "        axs[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        # Plot for the test set with consistent category order\n",
    "        sns.countplot(data=test, x=cat_col, palette=\"Set2\", ax=axs[1], order=categories)\n",
    "        axs[1].set_title(f\"Test - {cat_col}\", fontsize=16)\n",
    "        axs[1].set_xlabel(cat_col, fontsize=12)\n",
    "        axs[1].set_ylabel(\"Count\", fontsize=12)\n",
    "        axs[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# compare_categorical_columns(train, test, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### count + bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_countplot(df, cat_cols):\n",
    "\n",
    "    for cat_col in cat_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data=df, x=cat_col, palette=\"Set2\")\n",
    "        plt.title(f\"Count Plot of {cat_col}\", fontsize=16)\n",
    "        plt.xlabel(cat_col, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# plot_countplot(train, cat_cols)\n",
    "\n",
    "\n",
    "def plot_barplot(df, cat_cols, target):  # numrical target\n",
    "\n",
    "    for cat_col in cat_cols:\n",
    "        sns.barplot(data=df, x=cat_col, y=target, palette=\"Set2\")\n",
    "        plt.title(f\"Mean of {target.name} by {cat_col}\", fontsize=16)\n",
    "        plt.xlabel(cat_col, fontsize=12)\n",
    "        plt.ylabel(f\"Mean of {target.name}\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# plot_barplot(train, cat_cols, y)\n",
    "\n",
    "\n",
    "def plot_pie_chart(df, cat_cols):\n",
    "\n",
    "    for cat_col in cat_cols:\n",
    "        df[cat_col].value_counts().plot.pie(\n",
    "            autopct=\"%1.1f%%\", startangle=90, cmap=\"Set2\"\n",
    "        )\n",
    "        plt.title(f\"Pie Chart of {cat_col}\", fontsize=16)\n",
    "        plt.ylabel(\"\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# plot_pie_chart(train, cat_cols)\n",
    "\n",
    "\n",
    "def plot_boxplot(df, cat_cols, target):  # cat target\n",
    "\n",
    "    for cat_col in cat_cols:\n",
    "        sns.boxplot(data=df, x=cat_col, y=target, palette=\"Set2\")\n",
    "        plt.title(f\"Box Plot of {target.name} by {cat_col}\", fontsize=16)\n",
    "        plt.xlabel(cat_col, fontsize=12)\n",
    "        plt.ylabel(target.name, fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# plot_boxplot(train, cat_cols, y)\n",
    "\n",
    "\n",
    "def plot_violinplot(df, cat_cols, target):  # num target\n",
    "\n",
    "    for cat_col in cat_cols:\n",
    "        sns.violinplot(data=df, x=cat_col, y=target, palette=\"Set2\")\n",
    "        plt.title(f\"Violin Plot of {target.name} by {cat_col}\", fontsize=16)\n",
    "        plt.xlabel(cat_col, fontsize=12)\n",
    "        plt.ylabel(target.name, fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# plot_violinplot(train, cat_cols, y)\n",
    "\n",
    "\n",
    "def plot_pointplot(df, cat_cols, target):  # num target --> use to compare with num_cols\n",
    "\n",
    "    for cat_col in cat_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.pointplot(data=df, x=cat_col, y=target, palette=\"Set2\", estimator=\"mean\")\n",
    "        plt.title(f\"Mean of {target.name} by {cat_col}\", fontsize=16)\n",
    "        plt.xlabel(cat_col, fontsize=12)\n",
    "        plt.ylabel(f\"Mean of {target.name}\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# plot_pointplot(train, cat_cols, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### examine uniqe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_values(df, cat_cols):\n",
    "    for cat_col in cat_cols:\n",
    "        print(f\"Unique values in {cat_col}: {df[cat_col].unique()}\")\n",
    "\n",
    "\n",
    "# check_unique_values(train, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can do cat_cols vs num_cols by charts in cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lat_long_scatter(df, lat_col=\"geo.lat\", long_col=\"geo.lng\"):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.scatter(df[long_col], df[lat_col], alpha=0.6, color=\"blue\", edgecolors=\"k\")\n",
    "    plt.title(\"Scatter Plot of Latitude vs Longitude\", fontsize=16)\n",
    "    plt.xlabel(\"Longitude\", fontsize=12)\n",
    "    plt.ylabel(\"Latitude\", fontsize=12)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_lat_long_scatter(train)\n",
    "\n",
    "\n",
    "def plot_hexbin(df, lat_col=\"geo.lat\", long_col=\"geo.lng\", gridsize=50):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.hexbin(df[long_col], df[lat_col], gridsize=gridsize, cmap=\"Blues\", mincnt=1)\n",
    "    plt.colorbar(label=\"Count in Hexbin\")\n",
    "    plt.title(\"Hexbin Plot of Latitude vs Longitude\", fontsize=16)\n",
    "    plt.xlabel(\"Longitude\", fontsize=12)\n",
    "    plt.ylabel(\"Latitude\", fontsize=12)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_hexbin(train)\n",
    "\n",
    "\n",
    "def plot_heatmap(df, lat_col=\"geo.lat\", long_col=\"geo.lng\", cmap=\"viridis\"):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    sns.kdeplot(\n",
    "        data=df, x=long_col, y=lat_col, cmap=cmap, fill=True, thresh=0, levels=100\n",
    "    )\n",
    "    plt.title(\"Heatmap of Latitude vs Longitude\", fontsize=16)\n",
    "    plt.xlabel(\"Longitude\", fontsize=12)\n",
    "    plt.ylabel(\"Latitude\", fontsize=12)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_heatmap(train)\n",
    "\n",
    "\n",
    "def plot_lat_long_scatter2(df, lat_col=\"geo.lat\", long_col=\"geo.lng\", target=None):\n",
    "    x = df[(df[lat_col] != 0) & (df[long_col] != 0)][lat_col]  # Use lat_col\n",
    "    y = df[(df[lat_col] != 0) & (df[long_col] != 0)][long_col]  # Use long_col\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.scatterplot(x=x, y=y, hue=target)\n",
    "    sns.set(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "# plot_lat_long_scatter2(train, lat_col=\"LAT\", long_col=\"LON\", target=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(df, date_col, target_series):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    combined_df = pd.concat([df[date_col], target_series], axis=1)\n",
    "    combined_df.groupby(date_col)[target_series.name].mean().plot()\n",
    "\n",
    "    plt.title(f\"Time Series Plot of {target_series.name} Over Time\", fontsize=16)\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "    plt.ylabel(target_series.name, fontsize=12)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_time_series(train, 'date', y)\n",
    "\n",
    "\n",
    "def plot_datetime_histogram(df, date_col, granularity=\"hour\"):\n",
    "\n",
    "    if granularity == \"hour\":\n",
    "        df[\"time_component\"] = df[date_col].dt.hour\n",
    "        xlabel = \"Hour of Day\"\n",
    "    elif granularity == \"day\":\n",
    "        df[\"time_component\"] = df[date_col].dt.day\n",
    "        xlabel = \"Day of Month\"\n",
    "    elif granularity == \"month\":\n",
    "        df[\"time_component\"] = df[date_col].dt.month\n",
    "        xlabel = \"Month\"\n",
    "    elif granularity == \"week\":\n",
    "        df[\"time_component\"] = df[date_col].dt.isocalendar().week\n",
    "        xlabel = \"Week of Year\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid granularity. Choose from 'hour', 'day', 'month', or 'week'.\"\n",
    "        )\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df[\"time_component\"].hist(bins=30, color=\"blue\", alpha=0.7)\n",
    "    plt.title(f\"Distribution of {xlabel}\", fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(\"Frequency\", fontsize=12)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_datetime_histogram(train, 'date', 'hour')\n",
    "\n",
    "\n",
    "def plot_heatmap_by_day_hour(df, date_col, granularity=\"hour\"):\n",
    "    df[\"day_of_week\"] = df[date_col].dt.day_name()\n",
    "\n",
    "    # Handle granularity options\n",
    "    if granularity == \"hour\":\n",
    "        df[\"time_component\"] = df[date_col].dt.hour\n",
    "        xlabel = \"Hour of Day\"\n",
    "    elif granularity == \"day\":\n",
    "        df[\"time_component\"] = df[date_col].dt.day\n",
    "        xlabel = \"Day of Month\"\n",
    "    elif granularity == \"month\":\n",
    "        df[\"time_component\"] = df[date_col].dt.month\n",
    "        xlabel = \"Month\"\n",
    "    elif granularity == \"year\":\n",
    "        df[\"time_component\"] = df[date_col].dt.year\n",
    "        xlabel = \"Year\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid granularity. Choose from 'hour', 'day', 'month', or 'year'.\"\n",
    "        )\n",
    "\n",
    "    heatmap_data = (\n",
    "        df.groupby([\"day_of_week\", \"time_component\"]).size().unstack(fill_value=0)\n",
    "    )\n",
    "\n",
    "    ordered_days = [\n",
    "        \"Monday\",\n",
    "        \"Tuesday\",\n",
    "        \"Wednesday\",\n",
    "        \"Thursday\",\n",
    "        \"Friday\",\n",
    "        \"Saturday\",\n",
    "        \"Sunday\",\n",
    "    ]\n",
    "    heatmap_data = heatmap_data.reindex(ordered_days)  # Reorder index, not columns\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(heatmap_data, cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n",
    "    plt.title(f\"Heatmap of Counts by Day of Week and {xlabel}\", fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(\"Day of Week\", fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_heatmap_by_day_hour(train, 'date', 'hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enggineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df, num_cols, scaler_type=\"standard\"):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if scaler_type == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler_type == \"robust\":\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid scaler_type. Choose from 'standard', 'minmax', or 'robust'.\"\n",
    "        )\n",
    "\n",
    "    df_copy[num_cols] = scaler.fit_transform(df_copy[num_cols])\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_transform(df, group_by, target_col, method=\"mean\"):\n",
    "    valid_methods = [\"mean\", \"sum\", \"count\", \"median\", \"min\", \"max\", \"mode\"]\n",
    "    if method not in valid_methods:\n",
    "        raise ValueError(f\"Invalid method. Choose one of {valid_methods}\")\n",
    "\n",
    "    if method == \"mode\":\n",
    "        # Handle 'mode' separately with alignment\n",
    "        grouped = df.groupby(group_by)[target_col].agg(\n",
    "            lambda x: x.mode()[0] if not x.mode().empty else np.nan\n",
    "        )\n",
    "        transformed_series = df[group_by].map(grouped)\n",
    "    else:\n",
    "        # Ensure index alignment with the original DataFrame\n",
    "        grouped = df.groupby(group_by, sort=False)[target_col].transform(method)\n",
    "        transformed_series = pd.Series(grouped.values, index=df.index)\n",
    "\n",
    "    return transformed_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN + DBscan + kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_knn_dbscan_kmeans(\n",
    "    df,\n",
    "    cols,\n",
    "    method=\"knn\",\n",
    "    n_neighbors=5,\n",
    "    eps=0.5,\n",
    "    min_samples=5,\n",
    "    n_clusters=3,\n",
    "    elbow=False,\n",
    "    geo_cols=None,\n",
    "    datetime_cols=None,\n",
    "):\n",
    "    if geo_cols:\n",
    "        df[geo_cols] = StandardScaler().fit_transform(df[geo_cols])\n",
    "\n",
    "    if datetime_cols:\n",
    "        for col in datetime_cols:\n",
    "            df[col + \"_year\"] = df[col].dt.year\n",
    "            df[col + \"_month\"] = df[col].dt.month\n",
    "            df[col + \"_day\"] = df[col].dt.day\n",
    "            df[col + \"_hour\"] = df[col].dt.hour\n",
    "            df[col + \"_dayofweek\"] = df[col].dt.dayofweek\n",
    "\n",
    "        cols.extend([col + \"_year\" for col in datetime_cols])\n",
    "        cols.extend([col + \"_month\" for col in datetime_cols])\n",
    "        cols.extend([col + \"_day\" for col in datetime_cols])\n",
    "        cols.extend([col + \"_hour\" for col in datetime_cols])\n",
    "        cols.extend([col + \"_dayofweek\" for col in datetime_cols])\n",
    "\n",
    "    if method not in [\"knn\", \"dbscan\", \"kmeans\"]:\n",
    "        raise ValueError(\"Invalid method. Choose either 'knn', 'dbscan', or 'kmeans'.\")\n",
    "\n",
    "    if method == \"knn\":\n",
    "        if elbow:\n",
    "            mean_distances = []\n",
    "            neighbors_range = range(1, 15)\n",
    "            for k in neighbors_range:\n",
    "                knn = NearestNeighbors(n_neighbors=k)\n",
    "                knn.fit(df[cols])\n",
    "                distances, _ = knn.kneighbors(df[cols])\n",
    "                mean_distances.append(distances.mean(axis=1).mean())\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(neighbors_range, mean_distances, marker=\"o\")\n",
    "            plt.title(\"Elbow Method for Optimal K (KNN)\")\n",
    "            plt.xlabel(\"Number of Neighbors (K)\")\n",
    "            plt.ylabel(\"Mean Distance to Nearest Neighbors\")\n",
    "            plt.xticks(neighbors_range)\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "\n",
    "        knn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "        knn.fit(df[cols])\n",
    "        distances, indices = knn.kneighbors(df[cols])\n",
    "\n",
    "        df[\"knn_mean_distance\"] = distances.mean(axis=1)\n",
    "        df[\"knn_max_distance\"] = distances.max(axis=1)\n",
    "\n",
    "    elif method == \"dbscan\":\n",
    "        if elbow:\n",
    "            eps_values = [i / 100 for i in range(1, 200)]\n",
    "            num_clusters = []\n",
    "            for eps in eps_values:\n",
    "                dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "                clusters = dbscan.fit_predict(df[cols])\n",
    "                num_clusters.append(len(set(clusters)) - (1 if -1 in clusters else 0))\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(eps_values, num_clusters, marker=\"o\")\n",
    "            plt.title(\"Elbow Method for Optimal Epsilon (DBSCAN)\")\n",
    "            plt.xlabel(\"Epsilon\")\n",
    "            plt.ylabel(\"Number of Clusters\")\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        clusters = dbscan.fit_predict(df[cols])\n",
    "        df[\"dbscan_cluster\"] = clusters\n",
    "\n",
    "    elif method == \"kmeans\":\n",
    "        if elbow:\n",
    "            inertias = []\n",
    "            k_values = range(1, 15)\n",
    "            for k in k_values:\n",
    "                kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "                kmeans.fit(df[cols])\n",
    "                inertias.append(kmeans.inertia_)\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(k_values, inertias, marker=\"o\")\n",
    "            plt.title(\"Elbow Method for Optimal K (KMeans)\")\n",
    "            plt.xlabel(\"Number of Clusters (K)\")\n",
    "            plt.ylabel(\"Inertia\")\n",
    "            plt.xticks(k_values)\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        df[\"kmeans_cluster\"] = kmeans.fit_predict(df[cols])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### date time extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_datetime(df, datetime_col):\n",
    "    \"\"\"Extract datetime components and return a DataFrame with those components.\"\"\"\n",
    "    df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
    "    df[\"Year\"] = df[datetime_col].dt.year\n",
    "    df[\"Month\"] = df[datetime_col].dt.month\n",
    "    df[\"Day\"] = df[datetime_col].dt.day\n",
    "    df[\"Hour\"] = df[datetime_col].dt.hour\n",
    "    df[\"Minute\"] = df[datetime_col].dt.minute\n",
    "    df[\"Day_of_Week\"] = df[datetime_col].dt.dayofweek\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Delta\n",
    "# df[\"Rptd - date occ\"] = (df[\"Date Rptd\"] - df[\"DATE OCC\"]).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(\n",
    "    df,\n",
    "    cols=None,\n",
    "    n_components=2,\n",
    "    datetime_col=None,\n",
    "    lat_col=None,\n",
    "    long_col=None,\n",
    "    scaler_type=\"standard\",\n",
    "):\n",
    "    \"\"\"Apply PCA to specified columns after preprocessing datetime and geographical data.\"\"\"\n",
    "\n",
    "    if datetime_col and datetime_col in df.columns:\n",
    "        df = preprocess_datetime(df, datetime_col)\n",
    "\n",
    "    if lat_col in df.columns and long_col in df.columns:\n",
    "        df = scale_df(df, [lat_col, long_col], scaler_type)\n",
    "\n",
    "    if cols:\n",
    "        df_numerical = df[cols]\n",
    "    else:\n",
    "        numerical_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "        df_numerical = df[numerical_cols]\n",
    "\n",
    "    df_numerical = scale_df(df_numerical, df_numerical.columns, scaler_type)\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_features = pca.fit_transform(df_numerical)\n",
    "\n",
    "    for i in range(pca_features.shape[1]):\n",
    "        df[f\"PCA_Component_{i+1}\"] = pca_features[:, i]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sclae here\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "# df = scale_df(df, num_cols)\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mathemitical things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do your feature engineering here\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "# df['new_feature'] = np.where(df['feature1'].isna() | df['feature2'].isna(), np.nan, df['feature1'] * df['feature2'])\n",
    "\n",
    "# df['feature1_isna'] = df['feature1'].isna().astype(int)\n",
    "# df['feature2_isna'] = df['feature2'].isna().astype(int)\n",
    "# df['new_feature'] = df['feature1'] * df['feature2']\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make bins out of numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "def bin_numerical_feature(df, num_col, bins=None, new_col_name=None, bin_label=\"range\"):\n",
    "\n",
    "    if new_col_name is None:\n",
    "        new_col_name = f\"{num_col}_binned\"\n",
    "\n",
    "    if bins is None:\n",
    "        bins = int(np.ceil(np.log2(len(df[num_col]))) + 1)\n",
    "\n",
    "    # Create the binned feature (without labels for now)\n",
    "    binned_feature = pd.cut(df[num_col], bins=bins, include_lowest=True)\n",
    "\n",
    "    # Get the bin edges (bin intervals) from the pd.cut().categories\n",
    "    bin_edges = pd.cut(df[num_col], bins=bins, include_lowest=True).cat.categories\n",
    "\n",
    "    # Define how to calculate the labels based on the bin_label input\n",
    "    if bin_label == \"mean\":\n",
    "        bin_values = [(edge.left + edge.right) / 2 for edge in bin_edges]\n",
    "    elif bin_label == \"median\":\n",
    "        bin_values = [\n",
    "            df[(df[num_col] >= edge.left) & (df[num_col] <= edge.right)][\n",
    "                num_col\n",
    "            ].median()\n",
    "            for edge in bin_edges\n",
    "        ]\n",
    "    elif bin_label == \"min\":\n",
    "        bin_values = [edge.left for edge in bin_edges]\n",
    "    elif bin_label == \"max\":\n",
    "        bin_values = [edge.right for edge in bin_edges]\n",
    "    elif isinstance(bin_label, list):\n",
    "        # Use custom bin labels if provided\n",
    "        if len(bin_label) != len(bin_edges):\n",
    "            raise ValueError(\"The number of bin labels must match the number of bins.\")\n",
    "        bin_values = bin_label\n",
    "    else:\n",
    "        bin_values = (\n",
    "            bin_edges  # Default to range if no specific method or list is provided\n",
    "        )\n",
    "\n",
    "    # Map the bin indices to the selected bin labels (mean, median, etc.)\n",
    "    df[new_col_name] = binned_feature.map(\n",
    "        lambda x: bin_values[bin_edges.get_loc(x)] if pd.notna(x) else x\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "bins = [0, 12, 18, 30, 50, 100]\n",
    "custom_labels = [0, 1, 2, 3, 4]\n",
    "df = bin_numerical_feature(\n",
    "    df, num_cols[0], new_col_name=\"Age Groups\", bins=bins, bin_label=custom_labels\n",
    ")\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plonomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "def create_polynomial_features(df, num_cols, degree=2):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_features = poly.fit_transform(df[num_cols])\n",
    "    poly_feature_names = poly.get_feature_names_out(num_cols)\n",
    "\n",
    "    # Create a new DataFrame for polynomial features\n",
    "    df_new = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
    "\n",
    "    # Reset the index of both DataFrames to avoid index conflicts\n",
    "    df_combined = pd.concat(\n",
    "        [df.reset_index(drop=True), df_new.reset_index(drop=True)], axis=1\n",
    "    )\n",
    "\n",
    "    return df_combined, df_new\n",
    "\n",
    "\n",
    "# df_combined, df_new = create_polynomial_features(df, num_cols, degree=2)\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group transfrom\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "# df[\"new_feature\"] = group_transform(df, \"feature\", \"target_col\", \"mean\")\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmean + knn + dbscan\n",
    "df = pd.concat([train, test], axis=0)\n",
    "# df = create_features_knn_dbscan_kmeans(df, cols,  method=\"kmeans\", elbow=True, n_clusters=5)\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "# df = apply_pca(df, n_components=2))\n",
    "\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "def select_features_rfe(df, target, num_cols):\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model, n_features_to_select=5)\n",
    "    fit = rfe.fit(df[num_cols], target)\n",
    "\n",
    "    # Select columns (features) based on RFE support_\n",
    "    selected_columns = [col for col, support in zip(num_cols, fit.support_) if support]\n",
    "\n",
    "    # Return DataFrame with only the selected columns\n",
    "    return df[selected_columns]\n",
    "\n",
    "\n",
    "# df = select_features_rfe(df, y, num_cols)\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extract date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "# df = preprocess_datetime(df, datetime_col)\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you can do pca with date time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "# df = apply_pca(df, n_components=2))\n",
    "\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmean + knn + dbscan\n",
    "df = pd.concat([train, test], axis=0)\n",
    "# df = create_features_knn_dbscan_kmeans(df, cols, method=\"kmeans\", elbow=True, n_clusters=5)\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "# Label Encoding\n",
    "def label_encode(df, cat_cols):\n",
    "    le = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "# One-Hot Encoding\n",
    "def one_hot_encode(df, cat_cols):\n",
    "    df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "# Frequency Encoding\n",
    "def frequency_encode(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        freq = df[col].value_counts()\n",
    "        df[col] = df[col].map(freq)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Target Encoding\n",
    "def target_encode(df, cat_cols, target):\n",
    "    for col in cat_cols:\n",
    "        mean_encoded = df.groupby(col)[target].mean()\n",
    "        df[col] = df[col].map(mean_encoded)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Binary Encoding\n",
    "def binary_encode(df, cat_cols):\n",
    "    encoder = BinaryEncoder(cols=cat_cols)\n",
    "    df_encoded = encoder.fit_transform(df)\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "# Count Encoding\n",
    "def count_encode(df, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        counts = df[col].value_counts()\n",
    "        df[col] = df[col].map(counts)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Group Rare Categories\n",
    "def group_rare_categories(df, cat_cols, threshold=0.05):\n",
    "    for col in cat_cols:\n",
    "        counts = df[col].value_counts(normalize=True)\n",
    "        rare_categories = counts[counts < threshold].index\n",
    "        df[col] = df[col].replace(rare_categories, \"Other\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Create Interaction Feature\n",
    "def create_interaction_feature(df, col1, col2, new_col_name):\n",
    "    df[new_col_name] = df[col1].astype(str) + \"_\" + df[col2].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Ordinal Encoding\n",
    "def ordinal_encode(df, cat_cols, mapping_dict):\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].map(mapping_dict[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "# df = label_encode(df, cat_cols)\n",
    "# df = one_hot_encode(df, cat_cols)\n",
    "# df = frequency_encode(df, cat_cols)\n",
    "# df = target_encode(df, cat_cols, y)\n",
    "# df = binary_encode(df, cat_cols)\n",
    "# df = count_encode(df, cat_cols)\n",
    "# df = group_rare_categories(df, cat_cols)\n",
    "# df = create_interaction_feature(df, col1, col2, new_col_name)\n",
    "# df = ordinal_encode(df, cat_col, mapping)\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmean + knn + dbscan\n",
    "df = pd.concat([train, test], axis=0)\n",
    "# df = create_features_knn_dbscan_kmeans(df, cols,  method=\"kmeans\", elbow=True, n_clusters=5)\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "def create_geo_distance_features(df, lat_col, lon_col, reference_point=None):\n",
    "    geo_data = df[[lat_col, lon_col]].copy()\n",
    "\n",
    "    if reference_point is None:\n",
    "        # Set the reference point as the mean of latitude and longitude\n",
    "        reference_point = (geo_data[lat_col].mean(), geo_data[lon_col].mean())\n",
    "\n",
    "    # Feature: Distance from reference point\n",
    "    df[\"distance_from_reference\"] = geo_data.apply(\n",
    "        lambda row: geodesic((row[lat_col], row[lon_col]), reference_point).kilometers,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# df = create_geo_distance_features(df, \"lat_col\", \"lon_col\", reference_point=None)\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmean + knn + dbscan\n",
    "df = pd.concat([train, test], axis=0)\n",
    "# df = create_features_knn_dbscan_kmeans(df, cols,  method=\"kmeans\", elbow=True, n_clusters=5)\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "# df = apply_pca(df, n_components=2))\n",
    "\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_geometric_features(df, lat_col, lon_col, reference_point=None):\n",
    "\n",
    "    if reference_point is None:\n",
    "        reference_point = [df[lat_col].mean(), df[lon_col].mean()]\n",
    "\n",
    "    def calculate_bearing(row):\n",
    "        if reference_point:\n",
    "            lat1, lon1 = np.radians(row[lat_col]), np.radians(row[lon_col])\n",
    "            lat2, lon2 = np.radians(reference_point[0]), np.radians(reference_point[1])\n",
    "            d_lon = lon2 - lon1\n",
    "            x = np.sin(d_lon) * np.cos(lat2)\n",
    "            y = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(\n",
    "                d_lon\n",
    "            )\n",
    "            return (np.arctan2(x, y) + 2 * np.pi) % (2 * np.pi) * (180 / np.pi)\n",
    "        return np.nan\n",
    "\n",
    "    df[\"bearing\"] = df.apply(calculate_bearing, axis=1)\n",
    "\n",
    "    # Calculate relative positioning (N, S, E, W)\n",
    "    def relative_position(row):\n",
    "        if reference_point:\n",
    "            if row[lat_col] > reference_point[0]:\n",
    "                lat_pos = \"N\"\n",
    "            else:\n",
    "                lat_pos = \"S\"\n",
    "            if row[lon_col] > reference_point[1]:\n",
    "                lon_pos = \"E\"\n",
    "            else:\n",
    "                lon_pos = \"W\"\n",
    "            return f\"{lat_pos}_{lon_pos}\"\n",
    "        return np.nan\n",
    "\n",
    "    df[\"relative_position\"] = df.apply(relative_position, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "df = calculate_geometric_features(df, \"LAT\", \"LON\")\n",
    "\n",
    "train = df.iloc[: len(train)]\n",
    "test = df.iloc[len(train) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if a feature contains a list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Modus_Operandi\"] = df[\"Modus_Operandi\"].fillna(\"\")\n",
    "# df[\"Modus_Operandi\"] = df[\"Modus_Operandi\"].apply(lambda x: x.split() if x else [])\n",
    "\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# temp = mlb.fit_transform(df[\"Modus_Operandi\"])\n",
    "# temp = pd.DataFrame(temp, columns=mlb.classes_, index=df.index)\n",
    "# df = pd.concat([df, temp], axis=1)\n",
    "# df = df.drop(columns=[\"Modus_Operandi\"])\n",
    "\n",
    "\n",
    "# test[\"Modus_Operandi\"] = test[\"Modus_Operandi\"].fillna(\"\")\n",
    "# test[\"Modus_Operandi\"] = test[\"Modus_Operandi\"].apply(lambda x: x.split() if x else [])\n",
    "\n",
    "# temp2 = mlb.transform(test[\"Modus_Operandi\"])\n",
    "# temp2 = pd.DataFrame(temp2, columns=mlb.classes_, index=test.index)\n",
    "# test = pd.concat([test, temp2], axis=1)\n",
    "# test = test.drop(columns=[\"Modus_Operandi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More feature engeenier on you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutual_information(df, target_series, task=\"classification\"):\n",
    "    # Select the mutual information function based on the task type\n",
    "    if task == \"classification\":\n",
    "        mutual_info_func = mutual_info_classif\n",
    "    elif task == \"regression\":\n",
    "        mutual_info_func = mutual_info_regression\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid task. Choose either 'classification' or 'regression'.\"\n",
    "        )\n",
    "\n",
    "    # Calculate mutual information\n",
    "    mi_scores = mutual_info_func(df, target_series)\n",
    "\n",
    "    # Create a DataFrame for better visualization\n",
    "    mi_df = pd.DataFrame({\"Feature\": df.columns, \"Mutual Information\": mi_scores})\n",
    "    mi_df = mi_df.sort_values(by=\"Mutual Information\", ascending=False)\n",
    "\n",
    "    # Print the mutual information scores\n",
    "    print(mi_df)\n",
    "\n",
    "    # Plot the mutual information scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(mi_df[\"Feature\"], mi_df[\"Mutual Information\"], color=\"skyblue\")\n",
    "    plt.xlabel(\"Mutual Information\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(\"Mutual Information between Features and Target\")\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, X_val, y, y_val = train_test_split(train, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your metrics\n",
    "metrics = {\n",
    "    \"classification\": {\n",
    "        \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred),\n",
    "        \"f1_macro\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\"),\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"roc_auc\": roc_auc_score,  # For binary classification\n",
    "        \"roc_auc_ovr\": lambda y_true, y_pred: roc_auc_score(\n",
    "            y_true, y_pred, multi_class=\"ovr\"\n",
    "        ),  # For multi-class\n",
    "        \"roc_auc_ovo\": lambda y_true, y_pred: roc_auc_score(\n",
    "            y_true, y_pred, multi_class=\"ovo\"\n",
    "        ),  # For multi-class\n",
    "        \"log_loss\": log_loss,\n",
    "        \"confusion_matrix\": confusion_matrix,\n",
    "        \"classification_report\": lambda y_true, y_pred: classification_report(\n",
    "            y_true, y_pred\n",
    "        ),\n",
    "        \"roc_curve\": lambda y_true, y_pred: roc_curve(\n",
    "            y_true, y_pred\n",
    "        ),  # Returns FPR, TPR, thresholds\n",
    "    },\n",
    "    \"regression\": {\n",
    "        \"r2_score\": r2_score,\n",
    "        \"mean_squared_error\": mean_squared_error,\n",
    "        \"mean_absolute_error\": mean_absolute_error,\n",
    "        \"median_absolute_error\": median_absolute_error,\n",
    "        \"explained_variance_score\": explained_variance_score,\n",
    "        \"root_mean_squared_error\": lambda y_true, y_pred: mean_squared_error(\n",
    "            y_true, y_pred, squared=False\n",
    "        ),  # RMSE\n",
    "        \"mean_squared_log_error\": mean_squared_log_error,\n",
    "        \"max_error\": max_error,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression models and parameters\n",
    "regression_models = {\n",
    "    \"SVR\": {\n",
    "        \"model\": SVR(),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10, 100],\n",
    "            \"kernel\": [\"linear\", \"rbf\"],\n",
    "            \"gamma\": [\"scale\", \"auto\", 0.01, 0.1],\n",
    "            \"epsilon\": [0.1, 0.2, 0.5],  # Epsilon for margin of tolerance\n",
    "        },\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestRegressor(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"max_depth\": [None, 10, 20, 30],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4],  # Minimum samples at leaf node\n",
    "            \"max_features\": [\"auto\", \"sqrt\"],  # Number of features to consider\n",
    "        },\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBRegressor(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 6, 9, 12],\n",
    "            \"subsample\": [0.6, 0.8, 1.0],  # Fraction of samples to use\n",
    "            \"colsample_bytree\": [0.6, 0.8, 1.0],  # Fraction of features to use\n",
    "        },\n",
    "    },\n",
    "    \"LightGBM1\": {\n",
    "        \"model\": LGBMRegressor(),\n",
    "        \"params\": {\n",
    "            \"num_leaves\": [31, 50, 100],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"max_depth\": [-1, 10, 20],  # Default is -1 (no limit)\n",
    "            \"min_child_samples\": [20, 30],  # Minimum number of data points in a leaf\n",
    "        },\n",
    "    },\n",
    "    \"LightGBM5\": {\n",
    "        \"model\": LGBMRegressor(),\n",
    "        \"params\": {\n",
    "            \"num_leaves\": [31, 50, 100],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"boosting_type\": [\"gbdt\", \"dart\"],\n",
    "            \"max_depth\": [-1, 10, 20],\n",
    "        },\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"model\": CatBoostRegressor(silent=True),\n",
    "        \"params\": {\n",
    "            \"iterations\": [100, 200, 300],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"depth\": [6, 8, 10],\n",
    "            \"l2_leaf_reg\": [3, 5, 7],  # L2 regularization coefficient\n",
    "        },\n",
    "    },\n",
    "    \"Fastai\": {\n",
    "        \"model\": tabular_learner,\n",
    "        \"params\": {\n",
    "            \"layers\": [[200, 100], [400, 200]],\n",
    "            \"metrics\": [rmse],\n",
    "            \"emb_drop\": [0.1, 0.2],\n",
    "            \"drop_mult\": [0.5, 0.75],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification models and parameters\n",
    "classification_models = {\n",
    "    \"SVM\": {\n",
    "        \"model\": SVC(),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10, 100],\n",
    "            \"kernel\": [\"linear\", \"rbf\"],\n",
    "            \"gamma\": [\"scale\", \"auto\", 0.001, 0.01],\n",
    "            \"class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"max_depth\": [None, 10, 20, 30],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4],\n",
    "            \"max_features\": [\"auto\", \"sqrt\"],\n",
    "            \"class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(eval_metric=\"mlogloss\"),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 6, 9, 12],\n",
    "            \"subsample\": [0.6, 0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "            \"gamma\": [0, 0.1, 0.2],\n",
    "            \"scale_pos_weight\": [1, 10],\n",
    "        },\n",
    "    },\n",
    "    \"LightGBM1\": {\n",
    "        \"model\": LGBMClassifier(),\n",
    "        \"params\": {\n",
    "            \"num_leaves\": [31, 50, 70],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"max_depth\": [-1, 10, 20],\n",
    "            \"min_child_samples\": [10, 20],\n",
    "            \"class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "    },\n",
    "    \"LightGBM5\": {\n",
    "        \"model\": LGBMClassifier(),\n",
    "        \"params\": {\n",
    "            \"num_leaves\": [31, 50, 70],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"boosting_type\": [\"gbdt\", \"dart\"],\n",
    "            \"max_depth\": [-1, 10, 20],\n",
    "            \"min_child_samples\": [10, 20],\n",
    "            \"class_weight\": [None, \"balanced\"],\n",
    "        },\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"model\": CatBoostClassifier(silent=True),\n",
    "        \"params\": {\n",
    "            \"iterations\": [100, 200, 300],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"depth\": [6, 8, 10],\n",
    "            \"l2_leaf_reg\": [3, 5, 10],\n",
    "            \"bagging_temperature\": [0, 0.5, 1],\n",
    "            \"class_weights\": [None, \"balanced\"],\n",
    "        },\n",
    "    },\n",
    "    \"Fastai\": {\n",
    "        \"model\": tabular_learner,\n",
    "        \"params\": {\"layers\": [[200, 100], [300, 150]], \"metrics\": [accuracy]},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SearchCv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_train_models(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    models_dict,\n",
    "    metrics,\n",
    "    metric_name,\n",
    "    early_stopping_rounds=None,\n",
    "):\n",
    "    models = []\n",
    "\n",
    "    # Retrieve the correct scoring function based on the metric name\n",
    "    if metric_name in metrics[\"classification\"]:\n",
    "        scorer = make_scorer(metrics[\"classification\"][metric_name])\n",
    "    elif metric_name in metrics[\"regression\"]:\n",
    "        scorer = make_scorer(metrics[\"regression\"][metric_name])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported metric\")\n",
    "\n",
    "    for name, model_info in models_dict.items():\n",
    "        model = model_info[\"model\"]\n",
    "        params = model_info[\"params\"]\n",
    "\n",
    "        # Use GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, params, scoring=scorer, cv=10, n_jobs=-1)\n",
    "\n",
    "        # Fit the model, handling early stopping where applicable\n",
    "        if hasattr(model, \"fit\"):\n",
    "            if \"n_estimators\" in params and early_stopping_rounds is not None:\n",
    "                # For models that can accept an eval_set, include it\n",
    "                eval_set = [(X_val, y_val)]\n",
    "                if isinstance(model, (XGBRegressor, LGBMRegressor, CatBoostRegressor)):\n",
    "                    grid_search.fit(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        eval_set=eval_set,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=False,\n",
    "                    )\n",
    "                else:\n",
    "                    # For models without eval_set, simply fit normally\n",
    "                    grid_search.fit(X_train, y_train)\n",
    "            else:\n",
    "                grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_score = grid_search.best_score_\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        y_pred = best_model.predict(X_val)\n",
    "\n",
    "        # Calculate the validation score using the specified metric\n",
    "        val_score = (\n",
    "            metrics[\"classification\"][metric_name](y_val, y_pred)\n",
    "            if metric_name in metrics[\"classification\"]\n",
    "            else metrics[\"regression\"][metric_name](y_val, y_pred)\n",
    "        )\n",
    "\n",
    "        models.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"model\": best_model,\n",
    "                \"best_params\": best_params,\n",
    "                \"best_score\": best_score,\n",
    "                \"val_score\": val_score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Print the results for the current model\n",
    "        print(f\"Model: {name}\")\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"Best Score: {best_score:.4f}\")\n",
    "        print(f\"Validation Score: {val_score:.4f}\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "models.append(\n",
    "    fit_and_train_models(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        models_dict,\n",
    "        metrics,\n",
    "        metric_name,\n",
    "        early_stopping_rounds=20,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    is_classification=True,\n",
    "    eval_metric=\"f1_macro\",\n",
    "    time_limit=3600,\n",
    "    included_model_types=None,\n",
    "):\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    # Define all possible model types\n",
    "    if included_model_types is None:\n",
    "        included_model_types = [\n",
    "            \"GBM\",\n",
    "            \"CAT\",\n",
    "            \"XGB\",\n",
    "            \"RF\",\n",
    "            \"KNN\",\n",
    "            \"NN\",\n",
    "            \"LR\",\n",
    "            \"XT\",\n",
    "            \"FASTAI\",\n",
    "            \"NN_TORCH\",\n",
    "            \"ET\",\n",
    "            \"DTR\",\n",
    "            \"AB\",\n",
    "            \"GBR\",\n",
    "            \"H2O\",\n",
    "            \"LightGBM\",\n",
    "            \"CatBoost\",\n",
    "        ]\n",
    "\n",
    "    # Determine problem type for classification\n",
    "    if is_classification:\n",
    "        num_classes = len(set(y_train))\n",
    "        problem_type = \"binary\" if num_classes == 2 else \"multiclass\"\n",
    "    else:\n",
    "        problem_type = \"regression\"\n",
    "\n",
    "    # Set target column name\n",
    "    y_train.name = \"target_column_name\"\n",
    "\n",
    "    # Concatenate X and y for training data\n",
    "    train_data = X_train.copy()\n",
    "    train_data[\"target_column_name\"] = y_train\n",
    "\n",
    "    # Create a TabularPredictor with best parameters\n",
    "    predictor = TabularPredictor(\n",
    "        log_file_path=\"logs.txt\",\n",
    "        log_to_file=True,\n",
    "        label=\"target_column_name\",\n",
    "        eval_metric=eval_metric,\n",
    "        problem_type=problem_type,\n",
    "    )\n",
    "\n",
    "    # Fit the model with a time limit\n",
    "    predictor.fit(\n",
    "        train_data,\n",
    "        time_limit=time_limit,\n",
    "        presets=\"best_quality\",\n",
    "        num_bag_folds=10,\n",
    "        num_bag_sets=2,\n",
    "        # tuning_data=None,        # Disable internal splitting for validation\n",
    "        # holdout_frac=0,\n",
    "        num_stack_levels=2,\n",
    "        keep_only_best=True,\n",
    "        verbosity=2,\n",
    "        # num_gpus=1,\n",
    "        num_cpus=1,\n",
    "        # excluded_model_types=[\"KNN\", \"NN\", \"XT\", \"FASTAI\", \"NN_TORCH\"],\n",
    "        included_model_types=included_model_types,\n",
    "    )\n",
    "\n",
    "    # Get the leaderboard\n",
    "    leaderboard = predictor.leaderboard(silent=True)\n",
    "    best_model = predictor.get_model_best()\n",
    "    model_dict = predictor.get_model_full_dict()\n",
    "    if best_model in model_dict:\n",
    "        best_params = model_dict[best_model]\n",
    "        best_score = predictor.info()[\"val_score\"]\n",
    "    else:\n",
    "        print(f\"Model '{best_model}' not found in model_dict.\")\n",
    "        best_params, val_score = None, None\n",
    "\n",
    "    # You now have best_model, best_params, and val_score\n",
    "\n",
    "    # For Jupyter notebooks, display the styled leaderboard\n",
    "    try:\n",
    "        display(\n",
    "            leaderboard.style.background_gradient(subset=[\"score_val\"], cmap=\"RdYlGn\")\n",
    "        )\n",
    "    except ImportError:\n",
    "        # Convert leaderboard DataFrame to image using seaborn and matplotlib\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            leaderboard[[\"model\", \"score_val\"]].set_index(\"model\").T,\n",
    "            annot=True,\n",
    "            cmap=\"RdYlGn\",\n",
    "            cbar=False,\n",
    "            fmt=\".3f\",\n",
    "        )\n",
    "        plt.title(\"Leaderboard\")\n",
    "        plt.savefig(\"leaderboard.png\")\n",
    "        print(\n",
    "            \"Leaderboard saved as 'leaderboard.png'. Open the file to view the table.\"\n",
    "        )\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = predictor.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    if is_classification:\n",
    "        score = metrics[\"classification\"][eval_metric](y_test, y_pred)\n",
    "    else:\n",
    "        score = metrics[\"regression\"][eval_metric](y_test, y_pred)\n",
    "\n",
    "    print(f\"Model score: {score}\")\n",
    "\n",
    "    return {\n",
    "        \"name\": best_model,\n",
    "        \"model\": predictor,\n",
    "        \"best_params\": best_params,\n",
    "        \"best_score\": best_score,\n",
    "        \"val_score\": score,\n",
    "    }\n",
    "\n",
    "\n",
    "# Append the model's results to the models list\n",
    "model_result = train_and_evaluate_model(\n",
    "    X, y, X_val, y_val, is_classification=True, eval_metric=\"roc_auc\"\n",
    ")\n",
    "models.append(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom R2 Score metric\n",
    "class R2Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"r2_score\", **kwargs):\n",
    "        super(R2Score, self).__init__(name=name, **kwargs)\n",
    "        self.sum_squared_errors = self.add_weight(name=\"sse\", initializer=\"zeros\")\n",
    "        self.total_variance = self.add_weight(name=\"tv\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.sum_squared_errors.assign_add(tf.reduce_sum(tf.square(y_true - y_pred)))\n",
    "        self.total_variance.assign_add(\n",
    "            tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "        )\n",
    "\n",
    "    def result(self):\n",
    "        return 1 - (\n",
    "            self.sum_squared_errors / (self.total_variance + tf.keras.backend.epsilon())\n",
    "        )\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.sum_squared_errors.assign(0)\n",
    "        self.total_variance.assign(0)\n",
    "\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    # Cast y_true to float32 to match y_pred's dtype\n",
    "    y_true = K.cast(y_true, dtype=\"float32\")\n",
    "\n",
    "    # If multi-class, convert y_true to one-hot format\n",
    "    if K.ndim(y_pred) > 1:\n",
    "        y_true = K.one_hot(K.cast(y_true, \"int32\"), num_classes=K.shape(y_pred)[-1])\n",
    "\n",
    "    # Round predictions to nearest integer\n",
    "    y_pred = K.round(y_pred)\n",
    "\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "\n",
    "    # Return F1 Score\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "\n",
    "# Metrics dictionary\n",
    "metrics = {\n",
    "    \"classification\": {\n",
    "        # \"f1_macro\": tfa.metrics.F1Score(average='macro', num_classes=2),  # Updated instantiation\n",
    "        \"f1_macro\": custom_f1,\n",
    "        # \"f1_macro\": F1Macro(),\n",
    "        \"accuracy\": \"accuracy\",\n",
    "        \"precision\": \"precision\",\n",
    "        \"recall\": \"recall\",\n",
    "        \"roc_auc\": tf.keras.metrics.AUC(name=\"roc_auc\"),  # Updated AUC instantiation\n",
    "    },\n",
    "    \"regression\": {\n",
    "        \"mean_squared_error\": \"mean_squared_error\",\n",
    "        \"mean_absolute_error\": \"mean_absolute_error\",\n",
    "        \"r2_score\": R2Score(),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class NeuralNetworkModel:\n",
    "    def __init__(self, is_classification=True, metric_name=\"roc_auc\", n_runs=1):\n",
    "        self.is_classification = is_classification\n",
    "        self.metric_name = metric_name\n",
    "        self.n_runs = n_runs\n",
    "        self.models = []\n",
    "        self.ordinal_encoder = None\n",
    "\n",
    "    def create_and_train(self, X_train, y_train, X_val, y_val):\n",
    "        input_shape = (X_train.shape[1],)\n",
    "\n",
    "        for i in range(self.n_runs):\n",
    "            print(f\"Training run {i + 1}/{self.n_runs}\")\n",
    "            try:\n",
    "                if self.is_classification:\n",
    "                    self.ordinal_encoder = OrdinalEncoder()\n",
    "                    y_train_encoded = self.ordinal_encoder.fit_transform(\n",
    "                        y_train.values.reshape(-1, 1)\n",
    "                    ).ravel()\n",
    "                    y_val_encoded = self.ordinal_encoder.transform(\n",
    "                        y_val.values.reshape(-1, 1)\n",
    "                    ).ravel()\n",
    "                    y_train_encoded = y_train_encoded.astype(np.int32)\n",
    "                    y_val_encoded = y_val_encoded.astype(np.int32)\n",
    "                    num_classes = len(self.ordinal_encoder.categories_[0])\n",
    "                    if num_classes == 2:\n",
    "                        num_classes = 1\n",
    "                else:\n",
    "                    y_train_encoded = y_train\n",
    "                    y_val_encoded = y_val\n",
    "                    num_classes = 1\n",
    "\n",
    "                model = keras.Sequential(\n",
    "                    [\n",
    "                        layers.Input(shape=input_shape),\n",
    "                        layers.BatchNormalization(),\n",
    "                        layers.Dense(128, activation=\"relu\"),\n",
    "                        layers.Dropout(0.3),\n",
    "                        layers.BatchNormalization(),\n",
    "                        layers.Dense(64, activation=\"relu\"),\n",
    "                        layers.Dropout(0.3),\n",
    "                        layers.BatchNormalization(),\n",
    "                        layers.Dense(32, activation=\"relu\"),\n",
    "                        layers.Dense(\n",
    "                            num_classes,\n",
    "                            activation=(\n",
    "                                \"sigmoid\"\n",
    "                                if self.is_classification and num_classes == 1\n",
    "                                else \"softmax\" if self.is_classification else \"linear\"\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                loss_function = (\n",
    "                    \"binary_crossentropy\"\n",
    "                    if self.is_classification and num_classes == 1\n",
    "                    else (\n",
    "                        \"sparse_categorical_crossentropy\"\n",
    "                        if self.is_classification\n",
    "                        else \"mean_squared_error\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                model.compile(\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss=loss_function,\n",
    "                    metrics=[\n",
    "                        (\n",
    "                            metrics[\"classification\"][self.metric_name]\n",
    "                            if self.is_classification\n",
    "                            else metrics[\"regression\"][self.metric_name]\n",
    "                        )\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "                # early_stopping = callbacks.EarlyStopping(\n",
    "                #     monitor=\"val_loss\", patience=7, restore_best_weights=True\n",
    "                # )\n",
    "\n",
    "                # model_checkpoint = callbacks.ModelCheckpoint(\n",
    "                #     \"best_model.keras\", monitor=\"val_loss\", save_best_only=True\n",
    "                # )\n",
    "\n",
    "                early_stopping = callbacks.EarlyStopping(\n",
    "                    monitor=f\"val_{self.metric_name}\",\n",
    "                    patience=7,\n",
    "                    restore_best_weights=True,\n",
    "                )\n",
    "\n",
    "                model_checkpoint = callbacks.ModelCheckpoint(\n",
    "                    \"best_model.keras\",\n",
    "                    monitor=f\"val_{self.metric_name}\",\n",
    "                    save_best_only=True,\n",
    "                    # mode = \"max\",\n",
    "                )\n",
    "\n",
    "                history = model.fit(\n",
    "                    X_train,\n",
    "                    y_train_encoded,\n",
    "                    validation_data=(X_val, y_val_encoded),\n",
    "                    epochs=500,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=1,\n",
    "                )\n",
    "\n",
    "                model.load_weights(\"best_model.keras\")\n",
    "                y_pred = model.predict(X_val)\n",
    "\n",
    "                if self.is_classification:\n",
    "                    y_pred_classes = (\n",
    "                        (y_pred > 0.5).astype(int)\n",
    "                        if num_classes == 1\n",
    "                        else y_pred.argmax(axis=1)\n",
    "                    )\n",
    "                    score = metrics[\"regression\"][self.metric_name](y_val, y_pred)\n",
    "                    y_pred_labels = self.ordinal_encoder.inverse_transform(\n",
    "                        y_pred_classes.reshape(-1, 1)\n",
    "                    ).ravel()\n",
    "                else:\n",
    "                    score = metrics[\"regression\"][self.metric_name](y_val, y_pred)\n",
    "\n",
    "                print(\"Score:\", score)\n",
    "                best_score = min(history.history[\"val_loss\"])\n",
    "                best_params = model.get_config()\n",
    "\n",
    "                self.models.append(\n",
    "                    {\n",
    "                        \"name\": f\"NN_Run_{i + 1}\",\n",
    "                        \"model\": model,\n",
    "                        \"best_params\": best_params,\n",
    "                        \"best_score\": best_score,\n",
    "                        \"val_score\": score,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            except KeyError as e:\n",
    "                print(f\"Error: Metric '{e}' not found.\")\n",
    "                return None\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for model_info in self.models:\n",
    "            model = model_info[\"model\"]\n",
    "            y_pred = model.predict(X)\n",
    "\n",
    "            if self.is_classification:\n",
    "                y_pred_classes = (\n",
    "                    (y_pred > 0.5).astype(int)\n",
    "                    if y_pred.shape[-1] == 1\n",
    "                    else y_pred.argmax(axis=1)\n",
    "                )\n",
    "                y_pred_labels = self.ordinal_encoder.inverse_transform(\n",
    "                    y_pred_classes.reshape(-1, 1)\n",
    "                ).ravel()\n",
    "                predictions.append(y_pred_labels)\n",
    "            else:\n",
    "                predictions.append(y_pred)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# nn_model = NeuralNetworkModel(is_classification=True, metric_name=\"f1_macro\", n_runs=3)\n",
    "# nn_model.create_and_train(X, y, X_val, y_val)\n",
    "# predictions = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking & More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack with ready models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedModel:\n",
    "    def __init__(self, trained_models, meta_model, is_classification=True):\n",
    "        self.trained_models = trained_models  # List of trained models\n",
    "        self.meta_model = meta_model\n",
    "        self.is_classification = is_classification\n",
    "\n",
    "    def fit(self, X_val, y_val):\n",
    "        base_predictions = []\n",
    "\n",
    "        for model_info in self.trained_models:\n",
    "            model = model_info[\"model\"]  # Use already trained models\n",
    "            # Predict probabilities or fallback to class prediction\n",
    "            if self.is_classification:\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    y_pred = model.predict_proba(X_val)\n",
    "                else:\n",
    "                    y_pred = model.predict(X_val)\n",
    "                if y_pred.ndim == 1 or y_pred.shape[1] == 1:  # Binary classification\n",
    "                    y_pred = y_pred.reshape(-1, 1)\n",
    "                base_predictions.append(y_pred)\n",
    "            else:\n",
    "                y_pred = model.predict(X_val)\n",
    "                base_predictions.append(y_pred.reshape(-1, 1))\n",
    "\n",
    "        X_stack = np.hstack(base_predictions)\n",
    "        self.meta_model.fit(X_stack, y_val)\n",
    "\n",
    "    def predict(self, X):\n",
    "        base_predictions = []\n",
    "\n",
    "        for model_info in self.trained_models:\n",
    "            model = model_info[\"model\"]\n",
    "            if self.is_classification:\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    y_pred = model.predict_proba(X)\n",
    "                else:\n",
    "                    y_pred = model.predict(X)\n",
    "                if y_pred.ndim == 1 or y_pred.shape[1] == 1:\n",
    "                    y_pred = y_pred.reshape(-1, 1)\n",
    "                base_predictions.append(y_pred)\n",
    "            else:\n",
    "                y_pred = model.predict(X)\n",
    "                base_predictions.append(y_pred.reshape(-1, 1))\n",
    "\n",
    "        X_stack = np.hstack(base_predictions)\n",
    "        return self.meta_model.predict(X_stack)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Assuming you already have your trained models in a list as described\n",
    "# trained_models = [\n",
    "#     {\n",
    "#         \"name\": best_model,\n",
    "#         \"model\": predictor,\n",
    "#         \"best_params\": best_params,\n",
    "#         \"best_score\": best_score,\n",
    "#         \"val_score\": score,\n",
    "#     },\n",
    "#     ...\n",
    "# ]\n",
    "\n",
    "# Define your meta-model (for example, LogisticRegression for classification)\n",
    "# meta_model = LogisticRegression(\n",
    "#     C=1.0,\n",
    "#     penalty=\"l2\",\n",
    "#     solver=\"lbfgs\",\n",
    "#     max_iter=100,\n",
    "#     class_weight=\"balanced\",\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "# # Create an instance of StackedModel for classification\n",
    "# stacked_model = StackedModel(\n",
    "#     trained_models=trained_models, meta_model=meta_model, is_classification=True\n",
    "# )\n",
    "\n",
    "# # Fit the stacked model with validation data\n",
    "# stacked_model.fit(X_val, y_val)\n",
    "\n",
    "# # Predict using the stacked model\n",
    "# y_pred = stacked_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stack without ready models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedModel:\n",
    "    def __init__(self, models, meta_model, is_classification=True):\n",
    "        self.models = models\n",
    "        self.meta_model = meta_model\n",
    "        self.is_classification = is_classification\n",
    "        self.fitted_models = []\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        base_predictions = []\n",
    "\n",
    "        for model_info in self.models:\n",
    "            model = model_info[\"model\"]\n",
    "            model.fit(X_train, y_train)\n",
    "            # Predict probabilities or fallback to class prediction\n",
    "            if self.is_classification:\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    y_pred = model.predict_proba(X_val)\n",
    "                else:\n",
    "                    y_pred = model.predict(X_val)\n",
    "                if y_pred.ndim == 1 or y_pred.shape[1] == 1:  # Binary classification\n",
    "                    y_pred = y_pred.reshape(-1, 1)\n",
    "                base_predictions.append(y_pred)\n",
    "            else:\n",
    "                y_pred = model.predict(X_val)\n",
    "                base_predictions.append(y_pred.reshape(-1, 1))\n",
    "\n",
    "            self.fitted_models.append(model)\n",
    "\n",
    "        X_stack = np.hstack(base_predictions)\n",
    "        self.meta_model.fit(X_stack, y_val)\n",
    "\n",
    "    def predict(self, X):\n",
    "        base_predictions = []\n",
    "\n",
    "        for model in self.fitted_models:\n",
    "            if self.is_classification:\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    y_pred = model.predict_proba(X)\n",
    "                else:\n",
    "                    y_pred = model.predict(X)\n",
    "                if y_pred.ndim == 1 or y_pred.shape[1] == 1:\n",
    "                    y_pred = y_pred.reshape(-1, 1)\n",
    "                base_predictions.append(y_pred)\n",
    "            else:\n",
    "                y_pred = model.predict(X)\n",
    "                base_predictions.append(y_pred.reshape(-1, 1))\n",
    "\n",
    "        X_stack = np.hstack(base_predictions)\n",
    "        return self.meta_model.predict(X_stack)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define base models with expanded parameters including linear, logistic, and non-linear models\n",
    "models = [\n",
    "    {\n",
    "        \"name\": \"RandomForest\",\n",
    "        \"model\": RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            bootstrap=True,\n",
    "            random_state=42,\n",
    "            max_features=\"auto\",\n",
    "            oob_score=True,\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced\",\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"XGBoost\",\n",
    "        \"model\": XGBClassifier(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.01,\n",
    "            reg_lambda=0.01,\n",
    "            gamma=0.2,\n",
    "            scale_pos_weight=1,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LightGBM\",\n",
    "        \"model\": LGBMClassifier(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=8,\n",
    "            num_leaves=31,\n",
    "            min_child_samples=20,\n",
    "            min_child_weight=0.001,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.01,\n",
    "            reg_lambda=0.01,\n",
    "            random_state=42,\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CatBoost\",\n",
    "        \"model\": CatBoostClassifier(\n",
    "            iterations=200,\n",
    "            learning_rate=0.1,\n",
    "            depth=6,\n",
    "            l2_leaf_reg=3,\n",
    "            bootstrap_type=\"Bayesian\",\n",
    "            subsample=0.8,\n",
    "            random_state=42,\n",
    "            verbose=0,\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LinearRegression\",\n",
    "        \"model\": LinearRegression(),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LogisticRegression\",\n",
    "        \"model\": LogisticRegression(\n",
    "            C=1.0,\n",
    "            penalty=\"l2\",\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=100,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SVR\",\n",
    "        \"model\": SVR(\n",
    "            kernel=\"rbf\", C=1.0, epsilon=0.1\n",
    "        ),  # Example of a non-linear regression model\n",
    "    },\n",
    "]\n",
    "\n",
    "# Define your meta-model (for example, LogisticRegression for classification)\n",
    "# meta_model = LogisticRegression(\n",
    "#     C=1.0,\n",
    "#     penalty=\"l2\",\n",
    "#     solver=\"lbfgs\",\n",
    "#     max_iter=100,\n",
    "#     class_weight=\"balanced\",\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "# # Create an instance of StackedModel for classification\n",
    "# stacked_model = StackedModel(\n",
    "#     models=models, meta_model=meta_model, is_classification=True\n",
    "# )\n",
    "\n",
    "# # Fit the stacked model (example with training and validation data)\n",
    "# stacked_model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# # Predict using the stacked model\n",
    "# y_pred = stacked_model.predict(X_test)\n",
    "\n",
    "# # Plot meta-model weights\n",
    "# stacked_model.plot_model_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optuna!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "\n",
    "class ModelOptimizer:\n",
    "    def __init__(self, train, y, models=None, cv=5, n_trials=100, scoring=\"roc_auc\"):\n",
    "        logging.info(\n",
    "            \"Initializing ModelOptimizer with models=%s, cv=%d, n_trials=%d, and scoring=%s\",\n",
    "            models, cv, n_trials, scoring\n",
    "        )\n",
    "        self.train = train\n",
    "        self.y = y\n",
    "        self.cv = cv\n",
    "        self.n_trials = n_trials\n",
    "        self.scoring = scoring\n",
    "        self.best_params = {}\n",
    "        self.studies = {}\n",
    "\n",
    "        # Allow a list of models to be passed\n",
    "        self.models = models if models else [\"LGBMClassifier\", \"XGBClassifier\", \"RandomForestClassifier\", \"CatBoostClassifier\"]\n",
    "\n",
    "    def optimize_model(self, name, objective):\n",
    "        logging.info(\"Optimizing model: %s\", name)\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=self.n_trials)\n",
    "        self.best_params[name] = study.best_params\n",
    "        self.studies[name] = study\n",
    "        logging.info(\n",
    "            \"Optimization for %s completed. Best params: %s\",\n",
    "            name,\n",
    "            self.best_params[name],\n",
    "        )\n",
    "        return study.best_params\n",
    "\n",
    "    def objective_lgbm(self, trial):\n",
    "        lgbm_params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 70),\n",
    "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 100),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 1.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 1.0),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "            \"is_unbalance\": trial.suggest_categorical(\"is_unbalance\", [True, False]),\n",
    "        }\n",
    "        pipeline = Pipeline(\n",
    "            steps=[(\"lgbm\", LGBMClassifier(**lgbm_params, random_state=42, verbose=-1))]\n",
    "        )\n",
    "        return cross_val_score(\n",
    "            pipeline, self.train, self.y, cv=self.cv, scoring=self.scoring\n",
    "        ).mean()\n",
    "\n",
    "    def objective_xgb(self, trial):\n",
    "        xgb_params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.1, 1.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 1.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 1.0),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1, 10),\n",
    "        }\n",
    "        pipeline = Pipeline(\n",
    "            steps=[(\"xgb\", XGBClassifier(**xgb_params, random_state=42, verbosity=0))]\n",
    "        )\n",
    "        return cross_val_score(\n",
    "            pipeline, self.train, self.y, cv=self.cv, scoring=self.scoring\n",
    "        ).mean()\n",
    "\n",
    "    def objective_rf(self, trial):\n",
    "        rf_params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"max_depth\": trial.suggest_categorical(\"max_depth\", [10, 20, 30]),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4),\n",
    "            \"max_features\": trial.suggest_categorical(\n",
    "                \"max_features\", [\"auto\", \"sqrt\", \"log2\"]\n",
    "            ),\n",
    "            \"class_weight\": trial.suggest_categorical(\n",
    "                \"class_weight\", [\"balanced\", \"balanced_subsample\", None]\n",
    "            ),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        }\n",
    "        pipeline = Pipeline(\n",
    "            steps=[(\"rf\", RandomForestClassifier(**rf_params, random_state=42))]\n",
    "        )\n",
    "        return cross_val_score(\n",
    "            pipeline, self.train, self.y, cv=self.cv, scoring=self.scoring\n",
    "        ).mean()\n",
    "\n",
    "    def objective_catboost(self, trial):\n",
    "        catboost_params = {\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 500),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 1, 10),\n",
    "            \"border_count\": trial.suggest_int(\"border_count\", 32, 254),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1, 10),\n",
    "        }\n",
    "        pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\n",
    "                    \"catboost\",\n",
    "                    CatBoostClassifier(**catboost_params, silent=True, random_state=42),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        return cross_val_score(\n",
    "            pipeline, self.train, self.y, cv=self.cv, scoring=self.scoring\n",
    "        ).mean()\n",
    "\n",
    "    def run_optimization(self):\n",
    "        logging.info(\"Starting optimization for selected models: %s\", self.models)\n",
    "        \n",
    "        # Optimize only selected models\n",
    "        if \"LGBMClassifier\" in self.models:\n",
    "            self.optimize_model(\"LGBMClassifier\", self.objective_lgbm)\n",
    "        if \"XGBClassifier\" in self.models:\n",
    "            self.optimize_model(\"XGBClassifier\", self.objective_xgb)\n",
    "        if \"RandomForestClassifier\" in self.models:\n",
    "            self.optimize_model(\"RandomForestClassifier\", self.objective_rf)\n",
    "        if \"CatBoostClassifier\" in self.models:\n",
    "            self.optimize_model(\"CatBoostClassifier\", self.objective_catboost)\n",
    "        \n",
    "        logging.info(\"Model optimizations completed for: %s\", self.models)\n",
    "\n",
    "    def save_best_params(self, filename=\"best_model_params.json\"):\n",
    "        logging.info(\"Saving best parameters to %s\", filename)\n",
    "        with open(filename, \"w\") as file:\n",
    "            json.dump(self.best_params, file, indent=4)\n",
    "        logging.info(\"Best parameters saved\")\n",
    "\n",
    "    def get_voting_classifier(self):\n",
    "        logging.info(\"Creating VotingClassifier with best models\")\n",
    "        best_lgbm = LGBMClassifier(\n",
    "            **self.best_params.get(\"LGBMClassifier\", {}), random_state=42, verbose=-1\n",
    "        )\n",
    "        best_xgb = XGBClassifier(**self.best_params.get(\"XGBClassifier\", {}), random_state=42)\n",
    "        best_rf = RandomForestClassifier(\n",
    "            **self.best_params.get(\"RandomForestClassifier\", {}), random_state=42\n",
    "        )\n",
    "        best_catboost = CatBoostClassifier(\n",
    "            **self.best_params.get(\"CatBoostClassifier\", {}), random_state=42, silent=True\n",
    "        )\n",
    "\n",
    "        voting_clf = VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"xgb\", best_xgb),\n",
    "                (\"lgbm\", best_lgbm),\n",
    "                (\"rf\", best_rf),\n",
    "                (\"catboost\", best_catboost),\n",
    "            ],\n",
    "            voting=\"soft\",\n",
    "        )\n",
    "\n",
    "        return voting_clf\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# train, y = ...  # Your train data and target variable\n",
    "# selected_models = [\"LGBMClassifier\", \"XGBClassifier\"]  # List of models to optimize\n",
    "# optimizer = ModelOptimizer(train, y, models=selected_models, cv=5, n_trials=100, scoring=\"roc_auc\")\n",
    "# optimizer.run_optimization()\n",
    "# optimizer.save_best_params()\n",
    "\n",
    "# # Voting Classifier\n",
    "# voting_clf = optimizer.get_voting_classifier()\n",
    "\n",
    "# # Cross-validation\n",
    "# pipeline = Pipeline(steps=[(\"classifier\", voting_clf)])\n",
    "# scores = cross_val_score(pipeline, train, y, cv=5, scoring=\"roc_auc\")\n",
    "# print(f\"Ensemble Model AUC: {scores.mean()}  {scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import catboost\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.model_selection import KFold\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming you have your features X and target y\n",
    "# n_splits = 5\n",
    "# kf = KFold(n_splits=n_splits)\n",
    "# oof_predictions = np.zeros(X.shape[0])\n",
    "\n",
    "# for train_index, valid_index in kf.split(X):\n",
    "#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "#     model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6)\n",
    "#     model.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "\n",
    "#     # Store the out-of-fold predictions\n",
    "#     oof_predictions[valid_index] = model.predict(X_valid)\n",
    "\n",
    "# # Now oof_predictions can be used as a feature in another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import lightgbm as lgb\n",
    "\n",
    "\n",
    "# def objective(trial):\n",
    "#     param = {\n",
    "#         \"objective\": \"regression\",\n",
    "#         \"metric\": \"rmse\",\n",
    "#         \"verbosity\": -1,\n",
    "#         \"boosting_type\": \"gbdt\",\n",
    "#         \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "#         \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "#         \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
    "#     }\n",
    "\n",
    "#     dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "#     gbm = lgb.train(param, dtrain)\n",
    "#     preds = gbm.predict(X_test)\n",
    "#     rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "#     return rmse\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# study.optimize(objective, n_trials=100)\n",
    "# print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do add hyper parameter optimization by auto gen ! test all codes, define ways for OOF !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'crm cd': pred})\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
